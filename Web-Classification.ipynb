{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "* Step1: Testing with open source (bbc)\n",
    "* Step2: Applied Tf-idf to figure out the weightage of important keywords\n",
    "* Step3: Compare the metrics of two Classification Algorithms: Multinomial Naive Bayes and Support Vector Machine (SVM)\n",
    "* Step4: Calculate the prediction probability by taking the mean. \n",
    "* Step5: Run the real gambling links and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, io, re\n",
    "from bs4 import BeautifulSoup  \n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rite_links = ['https://www.bbc.com/sport/football/51685405',\n",
    "             'https://www.bbc.com/sport/rugby-union/51784446',\n",
    "             'https://www.bbc.com/sport/football/51784350',\n",
    "             'https://www.bbc.com/sport/football/51685402',\n",
    "             'https://www.bbc.com/sport/football/51685406',\n",
    "             'https://www.bbc.com/sport/football/51785880',\n",
    "             'https://www.bbc.com/sport/cricket/51784104',\n",
    "             'https://www.bbc.com/sport/football/51693762',\n",
    "             'https://www.bbc.com/sport/rugby-union/51745091',\n",
    "             'https://www.bbc.com/sport/football/51787338',\n",
    "             'https://www.bbc.com/sport/football/51793861',\n",
    "             'https://www.bbc.com/sport/football/51693759',\n",
    "             'https://www.bbc.com/sport/football/51693745',\n",
    "             'https://www.bbc.com/sport/football/51793861',\n",
    "             'https://www.bbc.com/sport/football/51787031',\n",
    "             'https://www.bbc.com/sport/football/51786497',\n",
    "             'https://www.bbc.com/sport/football/51163821',\n",
    "             'https://www.bbc.com/sport/football/51786554']\n",
    "\n",
    "wrong_links = ['https://www.bbc.com/news/uk-51800196',\n",
    "              'https://www.bbc.com/news/business-51796806',\n",
    "              'https://www.bbc.com/news/world-europe-51799956',\n",
    "              'http://www.bbc.com/travel/story/20200308-japans-ancient-way-to-save-the-planet',\n",
    "              'https://www.bbc.com/future/article/20200306-how-to-live-without-time']\n",
    "\n",
    "def preprocess(txt):\n",
    "    pattern1 = re.compile(r'<.*?>')   \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    lmt = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "    for i in range(len(txt)):  \n",
    "        txt[i] = str(txt[i]).lower()\n",
    "        for p1 in pattern1.findall(txt[i]):\n",
    "            txt[i] = txt[i].replace(p1, '').strip()\n",
    "            txt[i] = txt[i].translate(translator)\n",
    "            txt[i] = ' '.join([lmt.lemmatize(i) for i in txt[i].split()])\n",
    "\n",
    "    return ' '.join([sentence for sentence in txt])\n",
    "\n",
    "def test_doc(link):\n",
    "    page = requests.get(link)\n",
    "    text = BeautifulSoup(page.text, 'html.parser').findAll('p')\n",
    "    return preprocess(text)\n",
    "\n",
    "def based_docs(links):\n",
    "    docs = list()\n",
    "    for link in links:\n",
    "        page = requests.get(link)\n",
    "        text = BeautifulSoup(page.text, 'html.parser').findAll('p')\n",
    "        cleaned_text = preprocess(text)\n",
    "        docs.append(cleaned_text)\n",
    "    return docs # ==> return [a, b, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rite_docs = based_docs(rite_links)\n",
    "for i, v in enumerate(rite_docs):\n",
    "    rite_docs[i] = (rite_links[i], v, 1)\n",
    "\n",
    "wrong_docs = based_docs(wrong_links)\n",
    "for i, v in enumerate(wrong_docs):\n",
    "    wrong_docs[i] = (wrong_links[i], v, 0)\n",
    "    \n",
    "docs = rite_docs + wrong_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.bbc.com/sport/football/51685405</td>\n",
       "      <td>img alt height1 srchttpsa1apibbccoukhitxitiamp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.bbc.com/sport/rugby-union/51784446</td>\n",
       "      <td>img alt height1 srchttpsa1apibbccoukhitxitiamp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.bbc.com/sport/football/51784350</td>\n",
       "      <td>img alt height1 srchttpsa1apibbccoukhitxitiamp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.bbc.com/sport/football/51685402</td>\n",
       "      <td>img alt height1 srchttpsa1apibbccoukhitxitiamp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.bbc.com/sport/football/51685406</td>\n",
       "      <td>img alt height1 srchttpsa1apibbccoukhitxitiamp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            links  \\\n",
       "0     https://www.bbc.com/sport/football/51685405   \n",
       "1  https://www.bbc.com/sport/rugby-union/51784446   \n",
       "2     https://www.bbc.com/sport/football/51784350   \n",
       "3     https://www.bbc.com/sport/football/51685402   \n",
       "4     https://www.bbc.com/sport/football/51685406   \n",
       "\n",
       "                                                data  target  \n",
       "0  img alt height1 srchttpsa1apibbccoukhitxitiamp...       1  \n",
       "1  img alt height1 srchttpsa1apibbccoukhitxitiamp...       1  \n",
       "2  img alt height1 srchttpsa1apibbccoukhitxitiamp...       1  \n",
       "3  img alt height1 srchttpsa1apibbccoukhitxitiamp...       1  \n",
       "4  img alt height1 srchttpsa1apibbccoukhitxitiamp...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'links': [docs[i][0] for i in range(len(docs))],\n",
    "                   'data': [docs[i][1] for i in range(len(docs))],\n",
    "                'target': [docs[i][2] for i in range(len(docs))]})\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test dataset splitting + Applying Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.data, df.target\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df.data).toarray()\n",
    "X = TfidfTransformer().fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from Support Vector Machine algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "   micro avg       0.86      0.86      0.86         7\n",
      "   macro avg       0.43      0.50      0.46         7\n",
      "weighted avg       0.73      0.86      0.79         7\n",
      "\n",
      "0.8571428571428571\n",
      "[1 1 1 1 1 1 1]\n",
      "22    0\n",
      "17    1\n",
      "11    1\n",
      "15    1\n",
      "4     1\n",
      "13    1\n",
      "8     1\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from Multinomial Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "   micro avg       0.86      0.86      0.86         7\n",
      "   macro avg       0.43      0.50      0.46         7\n",
      "weighted avg       0.73      0.86      0.79         7\n",
      "\n",
      "0.8571428571428571\n",
      "[1 1 1 1 1 1 1]\n",
      "22    0\n",
      "17    1\n",
      "11    1\n",
      "15    1\n",
      "4     1\n",
      "13    1\n",
      "8     1\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of two methods are the same. Hence, it makes no difference to choose one over another. \n",
    "\n",
    "Probability when predicting a random value in accordance with its class [[prob to classify text, prob to classify target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14550839, 0.85449161],\n",
       "       [0.17164962, 0.82835038],\n",
       "       [0.05666256, 0.94333744],\n",
       "       [0.14296042, 0.85703958],\n",
       "       [0.0747194 , 0.9252806 ],\n",
       "       [0.07284682, 0.92715318],\n",
       "       [0.10888412, 0.89111588]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(url):\n",
    "    X, y = df.data, df.target\n",
    "\n",
    "    count_vect = CountVectorizer()\n",
    "    X = count_vect.fit_transform(df.data).toarray()\n",
    "    X = TfidfTransformer().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(10, 51))\n",
    "    \n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    probs = clf.predict_proba(X_test)\n",
    "    mean_prob = 0\n",
    "    for i in probs:\n",
    "        mean_prob += i[1]\n",
    "    mean_prob = mean_prob/len(probs)\n",
    "    \n",
    "    \n",
    "    #if url not in df['links']:\n",
    "    # depending on the prob => df.append(pd.DataFrame({'links':[], 'data':[], 'target': []}))\n",
    "    \n",
    "    if mean_prob >= 0.85:\n",
    "        return ('Gambling site.'), mean_prob #Should be Sport-site in this test\n",
    "    else:\n",
    "        return ('Non-gambling site.'), mean_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Gambling site.', 0.9253904470489545)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction('https://www.bbc.com/sport/football/51800667')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying Gamble Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamble_links = list()\n",
    "nongamble_links = list()\n",
    "\n",
    "with open('dir/links_gamble.txt', 'r') as f:\n",
    "    for link in f:\n",
    "        gamble_links.append(link)\n",
    "    f.close()\n",
    "\n",
    "with open('dir/links_nongamble.txt', 'r') as f:\n",
    "    for link in f:\n",
    "        nongamble_links.append(link)\n",
    "    f.close()\n",
    "\n",
    "gamble_docs = based_docs(gamble_links)\n",
    "for i, text in enumerate(gamble_docs):\n",
    "    gameble_docs[i] = (gamble_links[i], text, 1)\n",
    "\n",
    "nongameble_docs = based_docs(nongamble_links)\n",
    "for i, text in enumerat(nongamble_docs):\n",
    "    nongamble_docs[i] = (nongamble_links[i], text, 0)\n",
    "\n",
    "docs = gamble_docs + nongamble_docs\n",
    "df = pd.DataFram({'links': [docs[i][0] for i in range(len(docs))],\n",
    "                'data': [docs[i][1] for i in range(len(docs))],\n",
    "                'target': [docs[i][2] for i in range(len(docs))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction(your url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
