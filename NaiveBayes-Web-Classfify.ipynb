{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-classification with SVM and Naive Bayes\n",
    "Input:\n",
    "```\n",
    "    URL\n",
    "```\n",
    "Output:\n",
    "```\n",
    "    (BBC) Sport-site or Non-Sport site.\n",
    "```\n",
    "\n",
    "Files used:\n",
    "```\n",
    "link.txt\n",
    "false_links.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # work with html\n",
    "import requests \n",
    "\n",
    "import re #regular expression\n",
    "\n",
    "import string #to remove punctuation\n",
    "from nltk.corpus import stopwords #get stopwords\n",
    "from nltk.stem import WordNetLemmatizer #lemmatise words\n",
    "\n",
    "#tf-idf libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocess\n",
    "\n",
    "The 3 following functions are to trim the scraped texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_to_string(url):\n",
    "    '''\n",
    "        Return the Tag-type data found to String-type. \n",
    "    '''\n",
    "    page = requests.get(url)\n",
    "    parsing = BeautifulSoup(page.text, \"html.parser\")\n",
    "    texts_tag = parsing.findAll('title') + parsing.findAll('p')\n",
    "    texts = str()\n",
    "    for text in texts_tag:\n",
    "        texts += str(text) + ' '\n",
    "    return texts\n",
    "\n",
    "def tag_removal(texts):\n",
    "    '''\n",
    "        Find all the tag of <.*>\n",
    "    '''\n",
    "    pattern = r\"<.*?>\"\n",
    "    findings = re.findall(pattern, texts)\n",
    "    return findings\n",
    "\n",
    "def get_texts(texts):\n",
    "    '''\n",
    "        Replace all the tag of <.*> to get texts\n",
    "    '''\n",
    "    findings = tag_removal(texts)\n",
    "    for finding in findings:\n",
    "        texts = texts.replace(finding, \"\")\n",
    "    return texts       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string #to remove punctuation\n",
    "from nltk.corpus import stopwords #get stopwords\n",
    "from nltk.stem import WordNetLemmatizer #lemmatise words\n",
    "\n",
    "def preprocess(text_data):\n",
    "    '''\n",
    "        Remove unwanted and preprocess data\n",
    "    '''\n",
    "    #lower text\n",
    "    text_data = text_data.lower()\n",
    "    \n",
    "    #remove punctuation\n",
    "    text_data = text_data.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    #remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    for stopword in stop_words:\n",
    "        pattern = ' ' + stopword + ' '\n",
    "        try:\n",
    "            text_data = text_data.replace(pattern, \" \")\n",
    "        except:\n",
    "            None\n",
    "    \n",
    "    \n",
    "    #remove numbers\n",
    "    text_data = re.sub(r\"[0-9]\", \"\", text_data)\n",
    "    \n",
    "    #remove big whitespace\n",
    "    text_data = re.sub(r\"\\s{2,}\", \" \", text_data)\n",
    "    \n",
    "    #remove non-latin character\n",
    "    text_data = re.sub(r\"[^a-zA-Z\\s]\", \"\", text_data)\n",
    "    \n",
    "    #lemmatize\n",
    "    text_data = text_data.split(' ')\n",
    "    lmt = WordNetLemmatizer() \n",
    "    text_data = list(map(lmt.lemmatize, text_data))\n",
    "    \n",
    "    \n",
    "    return ' '.join(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(urls):\n",
    "    '''\n",
    "        Create a corpus\n",
    "    '''\n",
    "    \n",
    "    docs = list()\n",
    "    \n",
    "    for url in urls:\n",
    "        texts = tag_to_string(url)\n",
    "        findings = tag_removal(texts)\n",
    "        texts = get_texts(texts)\n",
    "        docs.append(preprocess(texts))\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `links.txt` file that contains links from BBC Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"links.txt\", \"r\") as f:\n",
    "    links = f.readlines()\n",
    "\n",
    "docs = corpus(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `false_links.txt` that contains links from other sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"false_links.txt\", \"r\") as f:\n",
    "    links = f.readlines()\n",
    "\n",
    "false_docs = corpus(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tuple with format:\n",
    "```\n",
    "    correct link: (data, 1)\n",
    "    wrong link: (data, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tuples = list()\n",
    "\n",
    "for doc in docs:\n",
    "    list_tuples.append((doc, 1))\n",
    "for f_doc in false_docs:\n",
    "    list_tuples.append((f_doc, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'data': [data[0] for data in list_tuples],\n",
    "    'target': [data[1] for data in list_tuples]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data schema of the Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data      object\n",
       "target     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Compute Tf-Idf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.data, df.target\n",
    "\n",
    "#remove common words\n",
    "cv = CountVectorizer(max_df=0.5)\n",
    "X = cv.fit_transform(df.data).toarray()\n",
    "\n",
    "#Compute the tf-idf value\n",
    "X = TfidfTransformer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ML libraries and Metric Scoring libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML libraries\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn import svm #support vector machine\n",
    "\n",
    "# Metric scoring\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform and observe the results from SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIXx:\n",
      " [[0 2]\n",
      " [0 6]]\n",
      "\n",
      "STATS REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         8\n",
      "   macro avg       0.38      0.50      0.43         8\n",
      "weighted avg       0.56      0.75      0.64         8\n",
      "\n",
      "\n",
      "ACCURACY SCORE:\n",
      " 0.75\n",
      "\n",
      "PREDICTION RESULTS:\n",
      " [1 1 1 1 1 1 1 1]\n",
      "\n",
      "DATA TESTED:\n",
      " 15    1\n",
      "2     1\n",
      "14    1\n",
      "23    0\n",
      "8     1\n",
      "4     1\n",
      "16    1\n",
      "20    0\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"CONFUSION MATRIXx:\\n\", confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nSTATS REPORT:\\n\", classification_report(y_test,y_pred))\n",
    "print(\"\\nACCURACY SCORE:\\n\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nPREDICTION RESULTS:\\n\", y_pred)\n",
    "print(\"\\nDATA TESTED:\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform and observe the results from Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIXx:\n",
      " [[1 1]\n",
      " [0 6]]\n",
      "\n",
      "STATS REPORT:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       0.86      1.00      0.92         6\n",
      "\n",
      "   micro avg       0.88      0.88      0.88         8\n",
      "   macro avg       0.93      0.75      0.79         8\n",
      "weighted avg       0.89      0.88      0.86         8\n",
      "\n",
      "\n",
      "ACCURACY SCORE:\n",
      " 0.875\n",
      "\n",
      "PREDICTION RESULTS:\n",
      " [1 1 1 1 1 1 1 0]\n",
      "\n",
      "DATA TESTED:\n",
      " 15    1\n",
      "2     1\n",
      "14    1\n",
      "23    0\n",
      "8     1\n",
      "4     1\n",
      "16    1\n",
      "20    0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"CONFUSION MATRIXx:\\n\", confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nSTATS REPORT:\\n\", classification_report(y_test,y_pred))\n",
    "print(\"\\nACCURACY SCORE:\\n\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nPREDICTION RESULTS:\\n\", y_pred)\n",
    "print(\"\\nDATA TESTED:\\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, Multinomial NB outperforms the SVM. Therefore, NB will be picked to perform classification.\n",
    "\n",
    "Below is the probability when predicting a random value in accordance with its class:```[prob to data, prob to target]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21686332, 0.78313668],\n",
       "       [0.16339472, 0.83660528],\n",
       "       [0.20974684, 0.79025316],\n",
       "       [0.31208506, 0.68791494],\n",
       "       [0.24157298, 0.75842702],\n",
       "       [0.2061244 , 0.7938756 ],\n",
       "       [0.15039716, 0.84960284],\n",
       "       [0.5676975 , 0.4323025 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf carries NB algorithm\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification \n",
    "\n",
    "Import random function to random sample the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(url):\n",
    "\n",
    "    \n",
    "    # define target\n",
    "    X, y = df.data, df.target\n",
    "    \n",
    "    #split train-test data\n",
    "    count_vect = CountVectorizer()\n",
    "    X = count_vect.fit_transform(df.data).toarray()\n",
    "    X = TfidfTransformer().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(10, 40))\n",
    "    \n",
    "    #select NB algorithm\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #prediction probabilities\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    \n",
    "    #calculate the average of probabilities\n",
    "    mean_prob = 0\n",
    "    for i in probs:\n",
    "        mean_prob += i[1]\n",
    "    mean_prob = mean_prob/len(probs)\n",
    "    \n",
    "\n",
    "    if mean_prob >= 0.85:\n",
    "        return ('Sport site.'), mean_prob #Should be Sport-site in this test\n",
    "    else:\n",
    "        return ('Non-sport site.'), mean_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Non-sport site.', 0.7634120338602803)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"https://www.bbc.com/news/world-us-canada-53788018\"\n",
    "prediction(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
