{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is my answer to Fsecure's test\n",
    "# Generate Statistics using MapReduce \n",
    "Input:\n",
    "```\n",
    "{\n",
    "    fullname1: {\n",
    "        'age': #value,\n",
    "        'address': #value,\n",
    "        'occupation': #value\n",
    "    },\n",
    "    fullname2: {\n",
    "        # as above\n",
    "    }\n",
    "}\n",
    "```\n",
    "Output:\n",
    "```\n",
    "{\n",
    "    'lastname1': {\n",
    "        'count': #occurence,\n",
    "        'age':{\n",
    "            'age1': #occurence\n",
    "            'age2': #occurence\n",
    "        },\n",
    "        'address':{\n",
    "            'address1': #occurence\n",
    "            'address2': #occurence\n",
    "        },\n",
    "        'occupation':{\n",
    "            'job1': #occurence\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import collections # for namedtupled and defaultdict\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"data.json\"\n",
    "def read_file(doc):\n",
    "    # open json file\n",
    "    with open(doc) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(data):\n",
    "    fullname = list()\n",
    "    age = list()\n",
    "    address = list()\n",
    "    occupation = list()\n",
    "    \n",
    "    # push the extracted data to the DataFrame\n",
    "    df = pd.DataFrame({'Full Name': fullname,\n",
    "         'Age': age,\n",
    "         'Address': address,\n",
    "         'Occupation': occupation})\n",
    "\n",
    "    # access to each item's data per format: {name: {v}}\n",
    "    for name, v in data.items():\n",
    "        fullname.append(name)\n",
    "\n",
    "        # access to {age: , address: , occupation: }\n",
    "        age.append(v['age'])\n",
    "        address.append(v['address'])\n",
    "        occupation.append(v['occupation'])\n",
    "    \n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV file\n",
    "to_dataframe(read_file(doc)).to_csv(r\"C:\\Users\\USER\\Desktop\\output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Stats\n",
    "\n",
    "Steps include:\n",
    "* Re-define the data schema, from dictionary to tuple.\n",
    "* Extract information of interest using MAP function.\n",
    "* Generate the statistics using REDUCE function.\n",
    "* Export the file to JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tuple \n",
    "Datapoint = collections.namedtuple('Datapoint', [\n",
    "    'fullname',\n",
    "    'age',\n",
    "    'address',\n",
    "    'occupation'\n",
    "])\n",
    "\n",
    "\n",
    "data = read_file(doc)\n",
    "# re-structure the data\n",
    "datapoints = list()\n",
    "for name, v in data.items():\n",
    "    datapoints.append(Datapoint(fullname=name, age=v['age'], address=v['address'], occupation=v['occupation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    '''\n",
    "        The function is to extract the information of interest\n",
    "    '''\n",
    "    return {'lastname': x.fullname.split(' ')[-1], 'age': x.age, 'address': x.address, 'occupation': x.occupation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Transform function with sets of Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the transform function with NamedTuple\n",
    "result = list(map(\n",
    "    transform,\n",
    "    datapoints\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a reducer to calculate the frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(acc, val):\n",
    "    '''\n",
    "        The function is used to calcualte the occurence\n",
    "        acc: accummulator, val: value\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        acc[val['lastname']]['count'] += 1 \n",
    "        \n",
    "    except:\n",
    "        # instantiate the nested dictionaries\n",
    "        acc[val['lastname']] = dict()\n",
    "        acc[val['lastname']]['age'] = dict()\n",
    "        acc[val['lastname']]['address'] = dict()\n",
    "        acc[val['lastname']]['occupation'] = dict()\n",
    "        acc[val['lastname']]['count'] = 1\n",
    " \n",
    "    # calculate the occurence of AGE\n",
    "    age = acc[val['lastname']]['age']\n",
    "    try:\n",
    "        age[str(val['age'])] += 1\n",
    "    except:\n",
    "        age[str(val['age'])] = 1\n",
    "        \n",
    "    \n",
    "    # calculate the occurence of ADDRESS\n",
    "    address = acc[val['lastname']]['address']\n",
    "    try:\n",
    "        address[val['address']] += 1\n",
    "    except:\n",
    "        address[val['address']] = 1\n",
    "        \n",
    "    \n",
    "    # calculate the occurence of OCCUPATION\n",
    "    occupation = acc[val['lastname']]['occupation']\n",
    "    try:\n",
    "        occupation[val['occupation']] += 1\n",
    "    except:\n",
    "        occupation[val['occupation']] = 1\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the occurence using Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a defaultdict\n",
    "dd = collections.defaultdict(list)\n",
    "\n",
    "# Calculate the occurence \n",
    "results = reduce(\n",
    "    reducer, \n",
    "    result, \n",
    "    dd\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the result as .JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\USER\\\\Desktop\\\\output.json\", \"w\") as json_file:\n",
    "    json.dump(results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Computing to reduce runtime for big file\n",
    "\n",
    "Multiprocess is a fork of `multiprocessing` developed to be compatible with IPython. More info: https://pypi.org/project/multiprocess/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multiprocess in d:\\users\\user\\anaconda3\\lib\\site-packages (0.70.10)\n",
      "Requirement already satisfied: dill>=0.3.2 in d:\\users\\user\\anaconda3\\lib\\site-packages (from multiprocess) (0.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install multiprocess\n",
    "import multiprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine having 1000 replicates of `data.json`, since 20 files doesn't make a diffence and 1 (fast) processor would yield better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'data.json'\n",
    "docs = [read_file(doc)]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-structure the data as above, but with an additional for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to complete: 4.41349\n"
     ]
    }
   ],
   "source": [
    "# maximum processors \n",
    "\n",
    "new_dd = collections.defaultdict(list)\n",
    "dpoints = list()\n",
    "for doc in docs:\n",
    "    for name, v in data.items():\n",
    "        dpoints.append(Datapoint(fullname=name, age=v['age'], address=v['address'], occupation=v['occupation']))\n",
    "\n",
    "        \n",
    "start = time.time()\n",
    "\n",
    "pool = multiprocess.Pool(4)\n",
    "p_mapped = pool.map(transform, dpoints)\n",
    "reduce(reducer, p_mapped, new_dd)\n",
    "\n",
    "end = time.time()\n",
    "print('\\nTime to complete: %.5f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to complete: 5.39989\n"
     ]
    }
   ],
   "source": [
    "# only 1 processor \n",
    "\n",
    "new_dd = collections.defaultdict(list)\n",
    "dpoints = list()\n",
    "for doc in docs:\n",
    "    for name, v in data.items():\n",
    "        dpoints.append(Datapoint(fullname=name, age=v['age'], address=v['address'], occupation=v['occupation']))\n",
    "\n",
    "        \n",
    "start = time.time()\n",
    "\n",
    "pool = multiprocess.Pool(1)\n",
    "p_mapped = pool.map(transform, dpoints)\n",
    "reduce(reducer, p_mapped, new_dd)\n",
    "\n",
    "end = time.time()\n",
    "print('\\nTime to complete: %.5f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
